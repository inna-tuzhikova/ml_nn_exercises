{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(train_fn: str,\n",
    "         test_fn: str):\n",
    "    train_df = pd.read_csv(train_fn)\n",
    "    test_df = pd.read_csv(test_fn)\n",
    "\n",
    "    X_train = np.array([[int(x) for x in s.split(',')] for s in train_df['Image']])\n",
    "    y_train = np.array([int(s) for s in train_df['Category']])\n",
    "\n",
    "    X_test = np.array([[int(x) for x in s.split(',')] for s in test_df['Image']])\n",
    "\n",
    "    return (X_train, y_train), X_test\n",
    "\n",
    "def binarize_image(pixels):\n",
    "    pixels = pixels.reshape(28, 28)\n",
    "    blur = cv2.GaussianBlur(pixels.astype(np.float32), (3,3), 0)\n",
    "    binary = cv2.threshold(blur.astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones(shape=(2,2), dtype=np.uint8)\n",
    "    pixels = cv2.morphologyEx(binary.astype(np.float32), cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    return pixels.reshape(28*28)\n",
    "\n",
    "def show_random_images(h=5, w=5):\n",
    "    idxs = np.random.randint(0, X_train.shape[0] - 1, size=w * h).tolist()\n",
    "    plt.figure(figsize=(w, h))\n",
    "    \n",
    "    for i in range(h * w):\n",
    "        plt.subplot(h, w, i+1)\n",
    "        image = X_train[idxs[i]].reshape(28,28)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(y_train[idxs[i]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), X_test = load(\n",
    "        train_fn='train.csv',\n",
    "        test_fn='test.csv')\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.apply_along_axis(binarize_image, axis=1, arr=X_train)\n",
    "X_test = np.apply_along_axis(binarize_image, axis=1, arr=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000,)\n",
      "(12000, 784) (12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 2.4059 - acc: 0.1119 - val_loss: 2.3035 - val_acc: 0.1118\n",
      "Epoch 2/500\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 2.3006 - acc: 0.1135 - val_loss: 2.3041 - val_acc: 0.1121\n",
      "Epoch 3/500\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 2.2435 - acc: 0.1457 - val_loss: 2.1870 - val_acc: 0.1643\n",
      "Epoch 4/500\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 2.1668 - acc: 0.1805 - val_loss: 2.1427 - val_acc: 0.1980\n",
      "Epoch 5/500\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 2.1222 - acc: 0.1849 - val_loss: 2.1087 - val_acc: 0.1854\n",
      "Epoch 6/500\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 2.1265 - acc: 0.1814 - val_loss: 2.1473 - val_acc: 0.1784\n",
      "Epoch 7/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 2.1145 - acc: 0.1824 - val_loss: 2.1553 - val_acc: 0.1746\n",
      "Epoch 8/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 2.1016 - acc: 0.1900 - val_loss: 2.1200 - val_acc: 0.2062\n",
      "Epoch 9/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 2.0883 - acc: 0.1922 - val_loss: 2.0657 - val_acc: 0.2010\n",
      "Epoch 10/500\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 2.0798 - acc: 0.1951 - val_loss: 2.0805 - val_acc: 0.1934\n",
      "Epoch 11/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 2.0785 - acc: 0.1921 - val_loss: 2.0422 - val_acc: 0.2044\n",
      "Epoch 12/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 2.0692 - acc: 0.1986 - val_loss: 2.0506 - val_acc: 0.2030\n",
      "Epoch 13/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 2.0530 - acc: 0.1981 - val_loss: 2.0342 - val_acc: 0.2137\n",
      "Epoch 14/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 2.0295 - acc: 0.2119 - val_loss: 2.0289 - val_acc: 0.2048\n",
      "Epoch 15/500\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 1.9972 - acc: 0.2280 - val_loss: 2.0195 - val_acc: 0.2147\n",
      "Epoch 16/500\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 1.9770 - acc: 0.2359 - val_loss: 1.9418 - val_acc: 0.2650\n",
      "Epoch 17/500\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 1.9562 - acc: 0.2420 - val_loss: 1.9413 - val_acc: 0.2413\n",
      "Epoch 18/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.9390 - acc: 0.2499 - val_loss: 1.9093 - val_acc: 0.2743\n",
      "Epoch 19/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.9135 - acc: 0.2534 - val_loss: 1.8895 - val_acc: 0.2849\n",
      "Epoch 20/500\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 1.8708 - acc: 0.2603 - val_loss: 1.8515 - val_acc: 0.2893\n",
      "Epoch 21/500\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.8554 - acc: 0.2627 - val_loss: 1.8608 - val_acc: 0.2578\n",
      "Epoch 22/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.8429 - acc: 0.2650 - val_loss: 1.8391 - val_acc: 0.2948\n",
      "Epoch 23/500\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.8293 - acc: 0.2643 - val_loss: 1.8202 - val_acc: 0.2815\n",
      "Epoch 24/500\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 1.8208 - acc: 0.2636 - val_loss: 1.8312 - val_acc: 0.2629\n",
      "Epoch 25/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.8141 - acc: 0.2602 - val_loss: 1.8265 - val_acc: 0.2241\n",
      "Epoch 26/500\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.8033 - acc: 0.2592 - val_loss: 1.8091 - val_acc: 0.2502\n",
      "Epoch 27/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7977 - acc: 0.2554 - val_loss: 1.8285 - val_acc: 0.2644\n",
      "Epoch 28/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7916 - acc: 0.2528 - val_loss: 1.8083 - val_acc: 0.2199\n",
      "Epoch 29/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7895 - acc: 0.2560 - val_loss: 1.7844 - val_acc: 0.2338\n",
      "Epoch 30/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7852 - acc: 0.2628 - val_loss: 1.7955 - val_acc: 0.2481\n",
      "Epoch 31/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7818 - acc: 0.2684 - val_loss: 1.7740 - val_acc: 0.2690\n",
      "Epoch 32/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7782 - acc: 0.2748 - val_loss: 1.7843 - val_acc: 0.3029\n",
      "Epoch 33/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7747 - acc: 0.2822 - val_loss: 1.8235 - val_acc: 0.2964\n",
      "Epoch 34/500\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 1.7732 - acc: 0.2818 - val_loss: 1.7864 - val_acc: 0.3052\n",
      "Epoch 35/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7745 - acc: 0.2835 - val_loss: 1.7852 - val_acc: 0.2560\n",
      "Epoch 36/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7691 - acc: 0.2794 - val_loss: 1.7905 - val_acc: 0.2833\n",
      "Epoch 37/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7681 - acc: 0.2816 - val_loss: 1.7672 - val_acc: 0.3003\n",
      "Epoch 38/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7684 - acc: 0.2805 - val_loss: 1.7867 - val_acc: 0.2946\n",
      "Epoch 39/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7668 - acc: 0.2788 - val_loss: 1.7662 - val_acc: 0.2661\n",
      "Epoch 40/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7643 - acc: 0.2804 - val_loss: 1.7712 - val_acc: 0.2529\n",
      "Epoch 41/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7637 - acc: 0.2801 - val_loss: 1.7863 - val_acc: 0.2752\n",
      "Epoch 42/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7603 - acc: 0.2778 - val_loss: 1.7758 - val_acc: 0.2560\n",
      "Epoch 43/500\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 1.7602 - acc: 0.2805 - val_loss: 1.7747 - val_acc: 0.2940\n",
      "Epoch 44/500\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 1.7605 - acc: 0.2771 - val_loss: 1.7805 - val_acc: 0.3113\n",
      "Epoch 45/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7569 - acc: 0.2792 - val_loss: 1.7656 - val_acc: 0.2859\n",
      "Epoch 46/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7538 - acc: 0.2830 - val_loss: 1.7499 - val_acc: 0.2988\n",
      "Epoch 47/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7540 - acc: 0.2825 - val_loss: 1.7637 - val_acc: 0.2911\n",
      "Epoch 48/500\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 1.7487 - acc: 0.2857 - val_loss: 1.7600 - val_acc: 0.2540\n",
      "Epoch 49/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7434 - acc: 0.2899 - val_loss: 1.7407 - val_acc: 0.3196\n",
      "Epoch 50/500\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.7375 - acc: 0.2889 - val_loss: 1.7317 - val_acc: 0.2767\n",
      "Epoch 51/500\n",
      "31360/48000 [==================>...........] - ETA: 0s - loss: 1.7322 - acc: 0.2922"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a0eff1eceb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0;31m# TODO(mrry): Switch to raising an exception from the SWIG wrapper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "y_train_enc = to_categorical(y_train)\n",
    "y_val_enc = to_categorical(y_val)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D())\n",
    "model.add(Dense(5, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_enc, epochs=500, verbose=1, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
